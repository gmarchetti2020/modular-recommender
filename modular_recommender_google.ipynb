{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# General Use\n",
    "import csv\n",
    "import sys\n",
    "#import requests\n",
    "import skimage.io\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from IPython.display import display, Image, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import cv2\n",
    "import h5py\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "np.random.seed(42)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras imports\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 \n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model, model_from_json\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Add, Dense, Reshape, Concatenate, Dropout,BatchNormalization, GaussianNoise\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings input\n",
    "ratingsFilePath=\"gs://gm-vr-input/data/ratings.csv\"\n",
    "# books input\n",
    "booksFilePath=\"gs://gm-vr-input/data/ratings.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2019-12-12 14:53\n"
     ]
    }
   ],
   "source": [
    "# load the user configs\n",
    "with open('conf/conf.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "model_name    = config[\"model\"]\n",
    "weights     = config[\"weights\"]\n",
    "include_top   = config[\"include_top\"]\n",
    "train_path    = config[\"train_path\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "test_size     = config[\"test_size\"]\n",
    "results     = config[\"results\"]\n",
    "model_path    = config[\"model_path\"]\n",
    "\n",
    "# start time\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights=weights)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] encoding labels...\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 8119\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 33029\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] completed label - 5264\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 10407\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 14266\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 14602\n",
      "[INFO] completed label - .DS_Store\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 9778\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 16018\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 1122\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 23395\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 4265\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 1549\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 1788\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 29608\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 1139\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] completed label - 5332\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 22265\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 409\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 11644\n",
      "[INFO] completed label - tagheuer\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 12788\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 10071\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 9673\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 2028\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 5669\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 4325\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 4741\n",
      "[INFO] completed label - rolex_proc\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 12790\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 24662\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] completed label - 6418\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 1784\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] completed label - 1779\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 4657\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] completed label - 2933\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] completed label - 4860\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 22626\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 4250\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] completed label - 3416\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 5529\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 20394\n",
      "[INFO] completed label - omega\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 9705\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 2928\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 3690\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 1551\n",
      "[INFO] completed label - iwc\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 2578\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 1558\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 8305\n",
      "[INFO] completed label - rolex\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 29594\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 10072\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] completed label - 17009\n",
      "[STATUS] training labels: [44 44 44 ... 14 14 14]\n",
      "[STATUS] training labels shape: (2412,)\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# encode the labels\n",
    "print (\"[INFO] encoding labels...\")\n",
    "le = LabelEncoder()\n",
    "le.fit([tl for tl in train_labels])\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "file_map=[]\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "count = 1\n",
    "for i, label in enumerate(train_labels):\n",
    "  cur_path = train_path + \"/\" + label\n",
    "  count = 1\n",
    "  for image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "    try:\n",
    "      img = image.load_img(image_path, target_size=image_size)\n",
    "      x = image.img_to_array(img)\n",
    "      x = np.expand_dims(x, axis=0)\n",
    "      x = preprocess_input(x)\n",
    "      # extract features  \n",
    "      feature = model.predict(x)\n",
    "      flat = feature.flatten()\n",
    "      features.append(flat)\n",
    "      labels.append(label)\n",
    "      file_map.append(image_path)  \n",
    "      print (\"[INFO] processed - \" + str(count))\n",
    "      count += 1\n",
    "    except:\n",
    "      pass\n",
    "  print (\"[INFO] completed label - \" + label)\n",
    "\n",
    "# encode the labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "\n",
    "# get the shape of training labels\n",
    "print (\"[STATUS] training labels: {}\".format(le_labels))\n",
    "print (\"[STATUS] training labels shape: {}\".format(le_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8119</td>\n",
       "      <td>[2.9428325, 1.3653524, 0.0, 0.0, 0.76257765, 0...</td>\n",
       "      <td>watches/train/8119/53016-334729812.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8119</td>\n",
       "      <td>[2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...</td>\n",
       "      <td>watches/train/8119/65002-592824102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8119</td>\n",
       "      <td>[1.3861163, 2.2683668, 0.0, 0.0, 0.81409585, 0...</td>\n",
       "      <td>watches/train/8119/45002508778094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8119</td>\n",
       "      <td>[5.459259, 3.270679, 0.0, 0.0, 0.59542555, 0.0...</td>\n",
       "      <td>watches/train/8119/676121532398843.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8119</td>\n",
       "      <td>[5.3857975, 4.2224317, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>watches/train/8119/557671296574805.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           features  \\\n",
       "0  8119  [2.9428325, 1.3653524, 0.0, 0.0, 0.76257765, 0...   \n",
       "1  8119  [2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...   \n",
       "2  8119  [1.3861163, 2.2683668, 0.0, 0.0, 0.81409585, 0...   \n",
       "3  8119  [5.459259, 3.270679, 0.0, 0.0, 0.59542555, 0.0...   \n",
       "4  8119  [5.3857975, 4.2224317, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                     path  \n",
       "0  watches/train/8119/53016-334729812.jpg  \n",
       "1  watches/train/8119/65002-592824102.jpg  \n",
       "2   watches/train/8119/45002508778094.jpg  \n",
       "3  watches/train/8119/676121532398843.jpg  \n",
       "4  watches/train/8119/557671296574805.jpg  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items=pd.DataFrame({'label': labels, 'features': features, 'path': file_map})\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2412, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2412\n",
       "unique      49\n",
       "top       5529\n",
       "freq        50\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['item_id']=items.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>path</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8119</td>\n",
       "      <td>[2.9428325, 1.3653524, 0.0, 0.0, 0.76257765, 0...</td>\n",
       "      <td>watches/train/8119/53016-334729812.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8119</td>\n",
       "      <td>[2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...</td>\n",
       "      <td>watches/train/8119/65002-592824102.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8119</td>\n",
       "      <td>[1.3861163, 2.2683668, 0.0, 0.0, 0.81409585, 0...</td>\n",
       "      <td>watches/train/8119/45002508778094.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8119</td>\n",
       "      <td>[5.459259, 3.270679, 0.0, 0.0, 0.59542555, 0.0...</td>\n",
       "      <td>watches/train/8119/676121532398843.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8119</td>\n",
       "      <td>[5.3857975, 4.2224317, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>watches/train/8119/557671296574805.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>17009</td>\n",
       "      <td>[0.24703631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>watches/train/17009/214270_17009-024.jpg</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>17009</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>watches/train/17009/296301000470319.jpg</td>\n",
       "      <td>2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>17009</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>watches/train/17009/26853637983957.jpg</td>\n",
       "      <td>2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>17009</td>\n",
       "      <td>[0.071288526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>watches/train/17009/214270_17009-033.jpg</td>\n",
       "      <td>2410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>17009</td>\n",
       "      <td>[0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>watches/train/17009/214270_17009-027.jpg</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2412 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           features  \\\n",
       "0      8119  [2.9428325, 1.3653524, 0.0, 0.0, 0.76257765, 0...   \n",
       "1      8119  [2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...   \n",
       "2      8119  [1.3861163, 2.2683668, 0.0, 0.0, 0.81409585, 0...   \n",
       "3      8119  [5.459259, 3.270679, 0.0, 0.0, 0.59542555, 0.0...   \n",
       "4      8119  [5.3857975, 4.2224317, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "...     ...                                                ...   \n",
       "2407  17009  [0.24703631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2408  17009  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2409  17009  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2410  17009  [0.071288526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "2411  17009  [0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                          path  item_id  \n",
       "0       watches/train/8119/53016-334729812.jpg        0  \n",
       "1       watches/train/8119/65002-592824102.jpg        1  \n",
       "2        watches/train/8119/45002508778094.jpg        2  \n",
       "3       watches/train/8119/676121532398843.jpg        3  \n",
       "4       watches/train/8119/557671296574805.jpg        4  \n",
       "...                                        ...      ...  \n",
       "2407  watches/train/17009/214270_17009-024.jpg     2407  \n",
       "2408   watches/train/17009/296301000470319.jpg     2408  \n",
       "2409    watches/train/17009/26853637983957.jpg     2409  \n",
       "2410  watches/train/17009/214270_17009-033.jpg     2410  \n",
       "2411  watches/train/17009/214270_17009-027.jpg     2411  \n",
       "\n",
       "[2412 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0        1      314       5\n",
       "1        1      439       3\n",
       "2        1      588       5\n",
       "3        1     1169       4\n",
       "4        1     1185       4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use mount point you previously created when setting up the cluster\n",
    "# Open and read the file from mounted storage\n",
    "container = \"Recommenders\"\n",
    "#inputFilePath = \"/dbfs/mnt/{}/{}\".format(container, 'ratings.csv') \n",
    "inputFilePath=\"Recommenders/data/ratings.csv\"\n",
    "dataset = pd.read_csv(inputFilePath)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset[dataset.book_id.between(0,2411)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns=({'book_id':'item_id'}), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240933</th>\n",
       "      <td>2411</td>\n",
       "      <td>50130</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240934</th>\n",
       "      <td>2411</td>\n",
       "      <td>51192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240935</th>\n",
       "      <td>2411</td>\n",
       "      <td>52012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240936</th>\n",
       "      <td>2411</td>\n",
       "      <td>52322</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240937</th>\n",
       "      <td>2411</td>\n",
       "      <td>53012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240938 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  user_id  rating\n",
       "0             1      314       5\n",
       "1             1      439       3\n",
       "2             1      588       5\n",
       "3             1     1169       4\n",
       "4             1     1185       4\n",
       "...         ...      ...     ...\n",
       "240933     2411    50130       4\n",
       "240934     2411    51192       3\n",
       "240935     2411    52012       3\n",
       "240936     2411    52322       5\n",
       "240937     2411    53012       5\n",
       "\n",
       "[240938 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240938.000000</td>\n",
       "      <td>240938.000000</td>\n",
       "      <td>240938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1205.534179</td>\n",
       "      <td>24627.420627</td>\n",
       "      <td>3.824706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>695.933953</td>\n",
       "      <td>14984.357458</td>\n",
       "      <td>1.010747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>603.000000</td>\n",
       "      <td>11691.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1205.000000</td>\n",
       "      <td>23291.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1808.000000</td>\n",
       "      <td>37097.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2411.000000</td>\n",
       "      <td>53424.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_id        user_id         rating\n",
       "count  240938.000000  240938.000000  240938.000000\n",
       "mean     1205.534179   24627.420627       3.824706\n",
       "std       695.933953   14984.357458       1.010747\n",
       "min         1.000000       1.000000       1.000000\n",
       "25%       603.000000   11691.000000       3.000000\n",
       "50%      1205.000000   23291.000000       4.000000\n",
       "75%      1808.000000   37097.000000       5.000000\n",
       "max      2411.000000   53424.000000       5.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        item_id  user_id  rating\n",
      "157096     1572     3022       3\n",
      "157542     1576    32803       5\n",
      "134319     1344    15524       5\n",
      "47161       472    33069       5\n",
      "75473       755    39013       2\n",
      "        item_id  user_id  rating\n",
      "57654       577    21759       3\n",
      "108082     1081    46513       5\n",
      "84121       842    17881       5\n",
      "190231     1903    37611       3\n",
      "84773       848    33357       4\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.1, random_state=42)\n",
    "print (train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  53424\n",
      "Number of items:  2411\n"
     ]
    }
   ],
   "source": [
    "n_users = dataset.user_id.max()\n",
    "print(\"Number of users: \", n_users)\n",
    "n_items = dataset.item_id.max()\n",
    "print(\"Number of items: \", n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_input = Input(shape=[1], name=\"Item-Input\")\n",
    "embedding_size = 10 #embedding dimensions\n",
    "item_embedding = Embedding(input_dim=n_items+1, output_dim=embedding_size, name=\"Item-Embedding\")(item_input)\n",
    "item_vec = Flatten(name=\"Flatten-items\")(item_embedding)\n",
    "\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(input_dim=n_users+1, output_dim=embedding_size, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "prod = Dot(name=\"Dot-Product\", axes=1)([item_vec, user_vec])\n",
    "model = Model([user_input, item_input], prod)\n",
    "model.compile('adam', 'mean_squared_error') # we are trying to approximate a rating, so we use a regression measure: mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 173475 samples, validate on 43369 samples\n",
      "Epoch 1/100\n",
      "173056/173475 [============================>.] - ETA: 0s - loss: 13.4307\n",
      "Epoch 00001: val_loss improved from inf to 8.13438, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 23s 135us/sample - loss: 13.4171 - val_loss: 8.1344\n",
      "Epoch 2/100\n",
      "173120/173475 [============================>.] - ETA: 0s - loss: 4.4183\n",
      "Epoch 00002: val_loss improved from 8.13438 to 2.69127, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 23s 132us/sample - loss: 4.4138 - val_loss: 2.6913\n",
      "Epoch 3/100\n",
      "173280/173475 [============================>.] - ETA: 0s - loss: 1.8756\n",
      "Epoch 00003: val_loss improved from 2.69127 to 1.78805, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 137us/sample - loss: 1.8752 - val_loss: 1.7881\n",
      "Epoch 4/100\n",
      "173152/173475 [============================>.] - ETA: 0s - loss: 1.2920\n",
      "Epoch 00004: val_loss improved from 1.78805 to 1.50805, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 25s 146us/sample - loss: 1.2914 - val_loss: 1.5080\n",
      "Epoch 5/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 1.0470\n",
      "Epoch 00005: val_loss improved from 1.50805 to 1.38128, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 139us/sample - loss: 1.0470 - val_loss: 1.3813\n",
      "Epoch 6/100\n",
      "173088/173475 [============================>.] - ETA: 0s - loss: 0.9122\n",
      "Epoch 00006: val_loss improved from 1.38128 to 1.30971, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 23s 131us/sample - loss: 0.9119 - val_loss: 1.3097\n",
      "Epoch 7/100\n",
      "173120/173475 [============================>.] - ETA: 0s - loss: 0.8259\n",
      "Epoch 00007: val_loss improved from 1.30971 to 1.26705, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 136us/sample - loss: 0.8258 - val_loss: 1.2671\n",
      "Epoch 8/100\n",
      "173216/173475 [============================>.] - ETA: 0s - loss: 0.7665\n",
      "Epoch 00008: val_loss improved from 1.26705 to 1.24037, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 137us/sample - loss: 0.7665 - val_loss: 1.2404\n",
      "Epoch 9/100\n",
      "173184/173475 [============================>.] - ETA: 0s - loss: 0.7231\n",
      "Epoch 00009: val_loss improved from 1.24037 to 1.21665, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 23s 132us/sample - loss: 0.7230 - val_loss: 1.2167\n",
      "Epoch 10/100\n",
      "173280/173475 [============================>.] - ETA: 0s - loss: 0.6899\n",
      "Epoch 00010: val_loss improved from 1.21665 to 1.20883, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 23s 133us/sample - loss: 0.6899 - val_loss: 1.2088\n",
      "Epoch 11/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.6632\n",
      "Epoch 00011: val_loss improved from 1.20883 to 1.20052, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 137us/sample - loss: 0.6632 - val_loss: 1.2005\n",
      "Epoch 12/100\n",
      "173056/173475 [============================>.] - ETA: 0s - loss: 0.6404\n",
      "Epoch 00012: val_loss improved from 1.20052 to 1.19634, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 136us/sample - loss: 0.6405 - val_loss: 1.1963\n",
      "Epoch 13/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.6204\n",
      "Epoch 00013: val_loss improved from 1.19634 to 1.19402, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 137us/sample - loss: 0.6204 - val_loss: 1.1940\n",
      "Epoch 14/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 0.6028\n",
      "Epoch 00014: val_loss improved from 1.19402 to 1.19082, saving model to Recommenders/output/dotproduct_model.h5\n",
      "173475/173475 [==============================] - 24s 138us/sample - loss: 0.6027 - val_loss: 1.1908\n",
      "Epoch 15/100\n",
      "173216/173475 [============================>.] - ETA: 0s - loss: 0.5859\n",
      "Epoch 00015: val_loss did not improve from 1.19082\n",
      "173475/173475 [==============================] - 24s 136us/sample - loss: 0.5860 - val_loss: 1.1961\n",
      "Epoch 16/100\n",
      "173088/173475 [============================>.] - ETA: 0s - loss: 0.5698\n",
      "Epoch 00016: val_loss did not improve from 1.19082\n",
      "173475/173475 [==============================] - 23s 134us/sample - loss: 0.5700 - val_loss: 1.1965\n",
      "Epoch 17/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 0.5547\n",
      "Epoch 00017: val_loss did not improve from 1.19082\n",
      "173475/173475 [==============================] - 23s 131us/sample - loss: 0.5547 - val_loss: 1.2021\n",
      "Epoch 18/100\n",
      "173088/173475 [============================>.] - ETA: 0s - loss: 0.5385\n",
      "Epoch 00018: val_loss did not improve from 1.19082\n",
      "173475/173475 [==============================] - 23s 130us/sample - loss: 0.5388 - val_loss: 1.2074\n",
      "Epoch 19/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.5227\n",
      "Epoch 00019: val_loss did not improve from 1.19082\n",
      "Restoring model weights from the end of the best epoch.\n",
      "173475/173475 [==============================] - 23s 133us/sample - loss: 0.5228 - val_loss: 1.2122\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 16\n",
    "\n",
    "container = \"Recommenders/\"\n",
    "outputFilePath=container+\"output/\"+'dotproduct_model.h5'\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=outputFilePath,\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                         patience=5,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights=True\n",
    "                         )\n",
    "\n",
    "history = model.fit([train.user_id.values, train.item_id.values], train.rating.values,\n",
    "                    epochs=nb_epoch,\n",
    "                    #batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, earlystop]).history\n",
    "\n",
    "\n",
    "# outputFilePath = \"/dbfs/mnt/{}/{}\".format(container, 'dotproduct_model.h5')\n",
    "\n",
    "model.save(outputFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train, Val Error\")\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the embeddings\n",
    "input_vecs = Concatenate()([user_vec, item_vec])\n",
    "#add a dense layer with regularization\n",
    "x = Dense(10, activation='relu')(input_vecs)\n",
    "x = Dropout(0.2)(x)\n",
    "#add an output layer\n",
    "y = Dense(1)(x)\n",
    "\n",
    "model = Model([user_input, item_input], y)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n",
      "Train on 173475 samples, validate on 43369 samples\n",
      "Epoch 1/100\n",
      "173248/173475 [============================>.] - ETA: 0s - loss: 1.2181\n",
      "Epoch 00001: val_loss improved from inf to 0.81986, saving model to Recommenders/output/deep_model_1.h5\n",
      "173475/173475 [==============================] - 25s 145us/sample - loss: 1.2175 - val_loss: 0.8199\n",
      "Epoch 2/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.7834\n",
      "Epoch 00002: val_loss improved from 0.81986 to 0.79210, saving model to Recommenders/output/deep_model_1.h5\n",
      "173475/173475 [==============================] - 22s 129us/sample - loss: 0.7833 - val_loss: 0.7921\n",
      "Epoch 3/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.6972\n",
      "Epoch 00003: val_loss improved from 0.79210 to 0.78440, saving model to Recommenders/output/deep_model_1.h5\n",
      "173475/173475 [==============================] - 23s 131us/sample - loss: 0.6972 - val_loss: 0.7844\n",
      "Epoch 4/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.6714\n",
      "Epoch 00004: val_loss did not improve from 0.78440\n",
      "173475/173475 [==============================] - 23s 135us/sample - loss: 0.6713 - val_loss: 0.7862\n",
      "Epoch 5/100\n",
      "173152/173475 [============================>.] - ETA: 0s - loss: 0.6559\n",
      "Epoch 00005: val_loss did not improve from 0.78440\n",
      "173475/173475 [==============================] - 23s 133us/sample - loss: 0.6560 - val_loss: 0.7893\n",
      "Epoch 6/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 0.6452\n",
      "Epoch 00006: val_loss did not improve from 0.78440\n",
      "173475/173475 [==============================] - 22s 125us/sample - loss: 0.6452 - val_loss: 0.7903\n",
      "Epoch 7/100\n",
      "173248/173475 [============================>.] - ETA: 0s - loss: 0.6362\n",
      "Epoch 00007: val_loss did not improve from 0.78440\n",
      "173475/173475 [==============================] - 22s 129us/sample - loss: 0.6362 - val_loss: 0.7885\n",
      "Epoch 8/100\n",
      "173280/173475 [============================>.] - ETA: 0s - loss: 0.6275\n",
      "Epoch 00008: val_loss did not improve from 0.78440\n",
      "Restoring model weights from the end of the best epoch.\n",
      "173475/173475 [==============================] - 21s 122us/sample - loss: 0.6274 - val_loss: 0.7956\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 16\n",
    "\n",
    "container = \"Recommenders/\"\n",
    "outputFilePath=container+\"output/\"+'deep_model_1.h5'\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=outputFilePath,\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                         patience=5,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights=True\n",
    "                         )\n",
    "\n",
    "history = model.fit([train.user_id, train.item_id], train.rating,\n",
    "                    epochs=nb_epoch,\n",
    "                    #batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, earlystop]).history\n",
    "\n",
    "\n",
    "# outputFilePath = \"/dbfs/mnt/{}/{}\".format(container, 'dotproduct_model.h5')\n",
    "\n",
    "model.save(outputFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train, Val Error\")\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "      <td>8119</td>\n",
       "      <td>[2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...</td>\n",
       "      <td>watches/train/8119/65002-592824102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>8119</td>\n",
       "      <td>[2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...</td>\n",
       "      <td>watches/train/8119/65002-592824102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "      <td>8119</td>\n",
       "      <td>[2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...</td>\n",
       "      <td>watches/train/8119/65002-592824102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>8119</td>\n",
       "      <td>[2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...</td>\n",
       "      <td>watches/train/8119/65002-592824102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "      <td>8119</td>\n",
       "      <td>[2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...</td>\n",
       "      <td>watches/train/8119/65002-592824102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240933</th>\n",
       "      <td>2411</td>\n",
       "      <td>50130</td>\n",
       "      <td>4</td>\n",
       "      <td>17009</td>\n",
       "      <td>[0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>watches/train/17009/214270_17009-027.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240934</th>\n",
       "      <td>2411</td>\n",
       "      <td>51192</td>\n",
       "      <td>3</td>\n",
       "      <td>17009</td>\n",
       "      <td>[0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>watches/train/17009/214270_17009-027.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240935</th>\n",
       "      <td>2411</td>\n",
       "      <td>52012</td>\n",
       "      <td>3</td>\n",
       "      <td>17009</td>\n",
       "      <td>[0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>watches/train/17009/214270_17009-027.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240936</th>\n",
       "      <td>2411</td>\n",
       "      <td>52322</td>\n",
       "      <td>5</td>\n",
       "      <td>17009</td>\n",
       "      <td>[0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>watches/train/17009/214270_17009-027.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240937</th>\n",
       "      <td>2411</td>\n",
       "      <td>53012</td>\n",
       "      <td>5</td>\n",
       "      <td>17009</td>\n",
       "      <td>[0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>watches/train/17009/214270_17009-027.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240938 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  user_id  rating  label  \\\n",
       "0             1      314       5   8119   \n",
       "1             1      439       3   8119   \n",
       "2             1      588       5   8119   \n",
       "3             1     1169       4   8119   \n",
       "4             1     1185       4   8119   \n",
       "...         ...      ...     ...    ...   \n",
       "240933     2411    50130       4  17009   \n",
       "240934     2411    51192       3  17009   \n",
       "240935     2411    52012       3  17009   \n",
       "240936     2411    52322       5  17009   \n",
       "240937     2411    53012       5  17009   \n",
       "\n",
       "                                                 features  \\\n",
       "0       [2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...   \n",
       "1       [2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...   \n",
       "2       [2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...   \n",
       "3       [2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...   \n",
       "4       [2.6267536, 0.77102214, 0.0, 0.0, 0.8126972, 0...   \n",
       "...                                                   ...   \n",
       "240933  [0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "240934  [0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "240935  [0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "240936  [0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "240937  [0.8800237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                            path  \n",
       "0         watches/train/8119/65002-592824102.jpg  \n",
       "1         watches/train/8119/65002-592824102.jpg  \n",
       "2         watches/train/8119/65002-592824102.jpg  \n",
       "3         watches/train/8119/65002-592824102.jpg  \n",
       "4         watches/train/8119/65002-592824102.jpg  \n",
       "...                                          ...  \n",
       "240933  watches/train/17009/214270_17009-027.jpg  \n",
       "240934  watches/train/17009/214270_17009-027.jpg  \n",
       "240935  watches/train/17009/214270_17009-027.jpg  \n",
       "240936  watches/train/17009/214270_17009-027.jpg  \n",
       "240937  watches/train/17009/214270_17009-027.jpg  \n",
       "\n",
       "[240938 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset=dataset.join(items.set_index('item_id'), on='item_id')\n",
    "new_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6267536 , 0.77102214, 0.        , ..., 5.035347  , 0.        ,\n",
       "       4.01118   ], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_input = Input(shape=[1], name=\"Item-Input\")\n",
    "embedding_size = 10\n",
    "item_embedding = Embedding(input_dim=n_items+1, output_dim=embedding_size, name=\"Item-Embedding\")(item_input)\n",
    "item_vec = Flatten(name=\"Flatten-Items\")(item_embedding)\n",
    "\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(input_dim=n_users+1, output_dim=embedding_size, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "metadata_input=Input(shape=[len(new_dataset.features[0])], name=\"Metadata-Input\")\n",
    "metadata_vec = Dense(10,\n",
    "                     #embedding_size,\n",
    "                     activation='relu', name=\"Metadata-Embedding\")(metadata_input)\n",
    "#metadata_vec = Flatten(name=\"Flatten-Metadata\")(metadata_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model with metadata and several regularization techniques to prevent overfitting\n",
    "input_vecs = Concatenate()([user_vec, item_vec, metadata_vec])\n",
    "#input_vecs = Dropout(0.5)(input_vecs)\n",
    "#x=BatchNormalization()(input_vecs)\n",
    "x = Dense(128, activation='relu',\n",
    "          #kernel_regularizer=regularizers.l2(0.01),\n",
    "          kernel_initializer='random_normal',\n",
    "          activity_regularizer=regularizers.l1(10e-4) #to prevent overfitting of training data\n",
    "         )(input_vecs)\n",
    "x = Dropout(0.2)(x)\n",
    "#x=BatchNormalization()(x)\n",
    "#output layer\n",
    "y = Dense(1)(x)\n",
    "\n",
    "new_model = Model([user_input, item_input, metadata_input], y)\n",
    "new_model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split for training\n",
    "train, test = train_test_split(new_dataset, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216844, 4096)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(train.features).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\", \"<class 'numpy.ndarray'>\"}), <class 'NoneType'>\n",
      "Train on 173475 samples, validate on 43369 samples\n",
      "Epoch 1/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 1.0131\n",
      "Epoch 00001: val_loss improved from inf to 0.89929, saving model to Recommenders/output/deep_model_2.h5\n",
      "173475/173475 [==============================] - 30s 170us/sample - loss: 1.0130 - val_loss: 0.8993\n",
      "Epoch 2/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.8224\n",
      "Epoch 00002: val_loss improved from 0.89929 to 0.78619, saving model to Recommenders/output/deep_model_2.h5\n",
      "173475/173475 [==============================] - 29s 167us/sample - loss: 0.8224 - val_loss: 0.7862\n",
      "Epoch 3/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 0.7551\n",
      "Epoch 00003: val_loss improved from 0.78619 to 0.76598, saving model to Recommenders/output/deep_model_2.h5\n",
      "173475/173475 [==============================] - 29s 166us/sample - loss: 0.7553 - val_loss: 0.7660\n",
      "Epoch 4/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.7280\n",
      "Epoch 00004: val_loss did not improve from 0.76598\n",
      "173475/173475 [==============================] - 28s 163us/sample - loss: 0.7279 - val_loss: 0.7667\n",
      "Epoch 5/100\n",
      "173248/173475 [============================>.] - ETA: 0s - loss: 0.7024\n",
      "Epoch 00005: val_loss improved from 0.76598 to 0.75728, saving model to Recommenders/output/deep_model_2.h5\n",
      "173475/173475 [==============================] - 27s 155us/sample - loss: 0.7026 - val_loss: 0.7573\n",
      "Epoch 6/100\n",
      "173120/173475 [============================>.] - ETA: 0s - loss: 0.6770\n",
      "Epoch 00006: val_loss did not improve from 0.75728\n",
      "173475/173475 [==============================] - 28s 161us/sample - loss: 0.6772 - val_loss: 0.7590\n",
      "Epoch 7/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 0.6571\n",
      "Epoch 00007: val_loss did not improve from 0.75728\n",
      "173475/173475 [==============================] - 28s 161us/sample - loss: 0.6571 - val_loss: 0.7652\n",
      "Epoch 8/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.6424- ETA: 0s \n",
      "Epoch 00008: val_loss did not improve from 0.75728\n",
      "173475/173475 [==============================] - 28s 160us/sample - loss: 0.6424 - val_loss: 0.7631\n",
      "Epoch 9/100\n",
      "173152/173475 [============================>.] - ETA: 0s - loss: 0.6283\n",
      "Epoch 00009: val_loss did not improve from 0.75728\n",
      "173475/173475 [==============================] - 27s 156us/sample - loss: 0.6283 - val_loss: 0.7708\n",
      "Epoch 10/100\n",
      "173280/173475 [============================>.] - ETA: 0s - loss: 0.6164\n",
      "Epoch 00010: val_loss did not improve from 0.75728\n",
      "Restoring model weights from the end of the best epoch.\n",
      "173475/173475 [==============================] - 28s 159us/sample - loss: 0.6164 - val_loss: 0.7801\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "## train new model with sampling\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "\n",
    "container = \"Recommenders/\"\n",
    "outputFilePath=container+\"output/\"+'deep_model_2.h5'\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=outputFilePath,\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                         patience=5,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights=True\n",
    "                         )\n",
    "\n",
    "history = new_model.fit([train.user_id, train.item_id, np.vstack(train.features)], train.rating,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, earlystop]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train, Val Error\")\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\", \"<class 'numpy.ndarray'>\"}), <class 'NoneType'>\n",
      "24094/24094 [==============================] - 1s 44us/sample - loss: 0.7646\n",
      "Evaluation loss:  0.7646312309942216\n"
     ]
    }
   ],
   "source": [
    "eval_loss=new_model.evaluate([test.user_id, test.item_id, np.vstack(test.features)], test.rating)\n",
    "print(\"Evaluation loss: \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to be done yet: autoencoder with metadata ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder to reduce dimension of feature vector to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 10\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 10 #embedding dimensions\n",
    "metadata_input_dim=len(new_dataset.features[0])\n",
    "encoding_dim=embedding_size\n",
    "print(metadata_input_dim, encoding_dim)\n",
    "#from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_input=Input(shape=(metadata_input_dim,), name=\"Metadata-Input\")\n",
    "encoded=GaussianNoise(stddev=0.1)(metadata_input)\n",
    "#encoded=Dropout(0.1)(encoded)\n",
    "encoded=Dense(256, \n",
    "              activation='relu'\n",
    "             )(encoded)\n",
    "#encoded=LeakyReLU(0.3)(encoded)\n",
    "encoder=Dense(encoding_dim, \n",
    "              activation='relu'\n",
    "             )(encoded)\n",
    "#encoder=LeakyReLU(0.3)(encoded)\n",
    "decoder=Dense(256, \n",
    "              activation='relu'\n",
    "             )(encoder)\n",
    "#decoder=LeakyReLU(0.3)(decoder)\n",
    "decoder=Dense(metadata_input_dim, activation='linear')(decoder)\n",
    "\n",
    "autoencoder=Model(inputs=metadata_input, outputs=decoder)\n",
    "ae_encoder=Model(inputs=metadata_input, outputs=encoder)\n",
    "\n",
    "encoded_input=Input(shape=(encoding_dim,))\n",
    "decoder_layer=autoencoder.layers[-2] # last 2 layers of autoencoder is a decoder\n",
    "ae_decoder=Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 173475 samples, validate on 43369 samples\n",
      "Epoch 1/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.2175\n",
      "Epoch 00001: val_loss improved from inf to 0.18191, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 100s 577us/sample - loss: 0.2175 - val_loss: 0.1819\n",
      "Epoch 2/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.1669\n",
      "Epoch 00002: val_loss improved from 0.18191 to 0.15908, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 91s 527us/sample - loss: 0.1669 - val_loss: 0.1591\n",
      "Epoch 3/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.1529\n",
      "Epoch 00003: val_loss improved from 0.15908 to 0.14917, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 89s 512us/sample - loss: 0.1529 - val_loss: 0.1492\n",
      "Epoch 4/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.1444\n",
      "Epoch 00004: val_loss improved from 0.14917 to 0.14117, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 91s 524us/sample - loss: 0.1444 - val_loss: 0.1412\n",
      "Epoch 5/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.1390\n",
      "Epoch 00005: val_loss improved from 0.14117 to 0.13815, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 95s 547us/sample - loss: 0.1390 - val_loss: 0.1382\n",
      "Epoch 6/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1348\n",
      "Epoch 00006: val_loss improved from 0.13815 to 0.13335, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 97s 560us/sample - loss: 0.1348 - val_loss: 0.1333\n",
      "Epoch 7/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.1308\n",
      "Epoch 00007: val_loss improved from 0.13335 to 0.12561, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 97s 560us/sample - loss: 0.1308 - val_loss: 0.1256\n",
      "Epoch 8/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.1233\n",
      "Epoch 00008: val_loss improved from 0.12561 to 0.11976, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 92s 531us/sample - loss: 0.1233 - val_loss: 0.1198\n",
      "Epoch 9/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.1184\n",
      "Epoch 00009: val_loss improved from 0.11976 to 0.11598, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 100s 576us/sample - loss: 0.1184 - val_loss: 0.1160\n",
      "Epoch 10/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1144\n",
      "Epoch 00010: val_loss improved from 0.11598 to 0.11102, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 96s 554us/sample - loss: 0.1144 - val_loss: 0.1110\n",
      "Epoch 11/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.1109\n",
      "Epoch 00011: val_loss improved from 0.11102 to 0.10904, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 100s 574us/sample - loss: 0.1109 - val_loss: 0.1090\n",
      "Epoch 12/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.1082\n",
      "Epoch 00012: val_loss improved from 0.10904 to 0.10780, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 92s 530us/sample - loss: 0.1082 - val_loss: 0.1078\n",
      "Epoch 13/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.1067\n",
      "Epoch 00013: val_loss improved from 0.10780 to 0.10636, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 93s 536us/sample - loss: 0.1067 - val_loss: 0.1064\n",
      "Epoch 14/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1054\n",
      "Epoch 00014: val_loss improved from 0.10636 to 0.10523, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 100s 578us/sample - loss: 0.1054 - val_loss: 0.1052\n",
      "Epoch 15/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1042\n",
      "Epoch 00015: val_loss improved from 0.10523 to 0.10463, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 95s 547us/sample - loss: 0.1042 - val_loss: 0.1046\n",
      "Epoch 16/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1032\n",
      "Epoch 00016: val_loss improved from 0.10463 to 0.10349, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 95s 548us/sample - loss: 0.1032 - val_loss: 0.1035\n",
      "Epoch 17/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.1024\n",
      "Epoch 00017: val_loss improved from 0.10349 to 0.10202, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 94s 544us/sample - loss: 0.1024 - val_loss: 0.1020\n",
      "Epoch 18/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1017\n",
      "Epoch 00018: val_loss improved from 0.10202 to 0.10130, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 94s 542us/sample - loss: 0.1017 - val_loss: 0.1013\n",
      "Epoch 19/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.1013\n",
      "Epoch 00019: val_loss did not improve from 0.10130\n",
      "173475/173475 [==============================] - 94s 544us/sample - loss: 0.1013 - val_loss: 0.1027\n",
      "Epoch 20/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1006\n",
      "Epoch 00020: val_loss did not improve from 0.10130\n",
      "173475/173475 [==============================] - 93s 537us/sample - loss: 0.1006 - val_loss: 0.1019\n",
      "Epoch 21/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.1006\n",
      "Epoch 00021: val_loss improved from 0.10130 to 0.10062, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 95s 546us/sample - loss: 0.1006 - val_loss: 0.1006\n",
      "Epoch 22/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0995\n",
      "Epoch 00022: val_loss improved from 0.10062 to 0.09858, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 94s 544us/sample - loss: 0.0995 - val_loss: 0.0986\n",
      "Epoch 23/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0992\n",
      "Epoch 00023: val_loss did not improve from 0.09858\n",
      "173475/173475 [==============================] - 85s 490us/sample - loss: 0.0992 - val_loss: 0.0999\n",
      "Epoch 24/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.0989\n",
      "Epoch 00024: val_loss did not improve from 0.09858\n",
      "173475/173475 [==============================] - 84s 486us/sample - loss: 0.0989 - val_loss: 0.0998\n",
      "Epoch 25/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.0985\n",
      "Epoch 00025: val_loss did not improve from 0.09858\n",
      "173475/173475 [==============================] - 94s 545us/sample - loss: 0.0984 - val_loss: 0.0990\n",
      "Epoch 26/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0982\n",
      "Epoch 00026: val_loss improved from 0.09858 to 0.09773, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 97s 557us/sample - loss: 0.0982 - val_loss: 0.0977\n",
      "Epoch 27/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0983\n",
      "Epoch 00027: val_loss did not improve from 0.09773\n",
      "173475/173475 [==============================] - 93s 536us/sample - loss: 0.0983 - val_loss: 0.0994\n",
      "Epoch 28/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0978\n",
      "Epoch 00028: val_loss did not improve from 0.09773\n",
      "173475/173475 [==============================] - 95s 546us/sample - loss: 0.0978 - val_loss: 0.0987\n",
      "Epoch 29/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0975\n",
      "Epoch 00029: val_loss improved from 0.09773 to 0.09716, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 183s 1ms/sample - loss: 0.0975 - val_loss: 0.0972\n",
      "Epoch 30/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0972\n",
      "Epoch 00030: val_loss did not improve from 0.09716\n",
      "173475/173475 [==============================] - 138s 797us/sample - loss: 0.0972 - val_loss: 0.0978\n",
      "Epoch 31/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.0969\n",
      "Epoch 00031: val_loss improved from 0.09716 to 0.09600, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 107s 618us/sample - loss: 0.0969 - val_loss: 0.0960\n",
      "Epoch 32/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0967\n",
      "Epoch 00032: val_loss improved from 0.09600 to 0.09582, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 106s 610us/sample - loss: 0.0967 - val_loss: 0.0958\n",
      "Epoch 33/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0964\n",
      "Epoch 00033: val_loss did not improve from 0.09582\n",
      "173475/173475 [==============================] - 98s 565us/sample - loss: 0.0964 - val_loss: 0.0970\n",
      "Epoch 34/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.0959\n",
      "Epoch 00034: val_loss did not improve from 0.09582\n",
      "173475/173475 [==============================] - 94s 543us/sample - loss: 0.0959 - val_loss: 0.0961\n",
      "Epoch 35/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0959\n",
      "Epoch 00035: val_loss improved from 0.09582 to 0.09491, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 91s 527us/sample - loss: 0.0959 - val_loss: 0.0949\n",
      "Epoch 36/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0956\n",
      "Epoch 00036: val_loss did not improve from 0.09491\n",
      "173475/173475 [==============================] - 90s 520us/sample - loss: 0.0956 - val_loss: 0.0965\n",
      "Epoch 37/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0956\n",
      "Epoch 00037: val_loss did not improve from 0.09491\n",
      "173475/173475 [==============================] - 92s 529us/sample - loss: 0.0956 - val_loss: 0.0949\n",
      "Epoch 38/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0952\n",
      "Epoch 00038: val_loss did not improve from 0.09491\n",
      "173475/173475 [==============================] - 103s 591us/sample - loss: 0.0952 - val_loss: 0.0950\n",
      "Epoch 39/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0950\n",
      "Epoch 00039: val_loss did not improve from 0.09491\n",
      "173475/173475 [==============================] - 93s 537us/sample - loss: 0.0950 - val_loss: 0.0962\n",
      "Epoch 40/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0950\n",
      "Epoch 00040: val_loss did not improve from 0.09491\n",
      "173475/173475 [==============================] - 95s 548us/sample - loss: 0.0950 - val_loss: 0.0972\n",
      "Epoch 41/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0948\n",
      "Epoch 00041: val_loss improved from 0.09491 to 0.09416, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 94s 543us/sample - loss: 0.0948 - val_loss: 0.0942\n",
      "Epoch 42/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0948\n",
      "Epoch 00042: val_loss did not improve from 0.09416\n",
      "173475/173475 [==============================] - 101s 583us/sample - loss: 0.0948 - val_loss: 0.0942\n",
      "Epoch 43/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0947\n",
      "Epoch 00043: val_loss improved from 0.09416 to 0.09407, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 90s 517us/sample - loss: 0.0947 - val_loss: 0.0941\n",
      "Epoch 44/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0946\n",
      "Epoch 00044: val_loss did not improve from 0.09407\n",
      "173475/173475 [==============================] - 93s 538us/sample - loss: 0.0946 - val_loss: 0.0941\n",
      "Epoch 45/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.0949\n",
      "Epoch 00045: val_loss did not improve from 0.09407\n",
      "173475/173475 [==============================] - 103s 593us/sample - loss: 0.0949 - val_loss: 0.0960\n",
      "Epoch 46/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0952\n",
      "Epoch 00046: val_loss improved from 0.09407 to 0.09375, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 94s 540us/sample - loss: 0.0952 - val_loss: 0.0937\n",
      "Epoch 47/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0947\n",
      "Epoch 00047: val_loss improved from 0.09375 to 0.09294, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 118s 680us/sample - loss: 0.0947 - val_loss: 0.0929\n",
      "Epoch 48/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.0947\n",
      "Epoch 00048: val_loss did not improve from 0.09294\n",
      "173475/173475 [==============================] - 118s 680us/sample - loss: 0.0947 - val_loss: 0.0943\n",
      "Epoch 49/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 0.0944\n",
      "Epoch 00049: val_loss did not improve from 0.09294\n",
      "173475/173475 [==============================] - 91s 523us/sample - loss: 0.0944 - val_loss: 0.0931\n",
      "Epoch 50/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0945\n",
      "Epoch 00050: val_loss did not improve from 0.09294\n",
      "173475/173475 [==============================] - 90s 519us/sample - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 51/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 0.0943\n",
      "Epoch 00051: val_loss did not improve from 0.09294\n",
      "173475/173475 [==============================] - 90s 519us/sample - loss: 0.0943 - val_loss: 0.0952\n",
      "Epoch 52/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0943\n",
      "Epoch 00052: val_loss did not improve from 0.09294\n",
      "173475/173475 [==============================] - 92s 530us/sample - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 53/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0941\n",
      "Epoch 00053: val_loss did not improve from 0.09294\n",
      "173475/173475 [==============================] - 103s 591us/sample - loss: 0.0941 - val_loss: 0.0941\n",
      "Epoch 54/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0942\n",
      "Epoch 00054: val_loss did not improve from 0.09294\n",
      "173475/173475 [==============================] - 106s 610us/sample - loss: 0.0942 - val_loss: 0.0934\n",
      "Epoch 55/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0945\n",
      "Epoch 00055: val_loss improved from 0.09294 to 0.09284, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 105s 605us/sample - loss: 0.0945 - val_loss: 0.0928\n",
      "Epoch 56/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0941\n",
      "Epoch 00056: val_loss improved from 0.09284 to 0.09283, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 119s 687us/sample - loss: 0.0941 - val_loss: 0.0928\n",
      "Epoch 57/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0939\n",
      "Epoch 00057: val_loss improved from 0.09283 to 0.09201, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 103s 591us/sample - loss: 0.0939 - val_loss: 0.0920\n",
      "Epoch 58/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0936\n",
      "Epoch 00058: val_loss did not improve from 0.09201\n",
      "173475/173475 [==============================] - 100s 575us/sample - loss: 0.0936 - val_loss: 0.0934\n",
      "Epoch 59/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 0.0938\n",
      "Epoch 00059: val_loss did not improve from 0.09201\n",
      "173475/173475 [==============================] - 97s 558us/sample - loss: 0.0938 - val_loss: 0.0927\n",
      "Epoch 60/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 0.0935\n",
      "Epoch 00060: val_loss improved from 0.09201 to 0.09196, saving model to Recommenders/output/feature_autoencoder_model_1.h5\n",
      "173475/173475 [==============================] - 101s 581us/sample - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 61/100\n",
      " 96992/173475 [===============>..............] - ETA: 42s - loss: 0.0935WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      " 97024/173475 [===============>..............] - ETA: 42s - loss: 0.0935"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-99e0c1d4390a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     callbacks=[checkpointer, earlystop]).history\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## train autoencoder model with sampling\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "\n",
    "container = \"Recommenders/\"\n",
    "outputFilePath=container+\"output/\"+'feature_autoencoder_model_1.h5'\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=outputFilePath,\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                         patience=10,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights=True\n",
    "                         )\n",
    "\n",
    "history = autoencoder.fit(np.vstack(train.features), np.vstack(train.features),\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, earlystop]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train, Val Error\")\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_encoder=load_model('Recommenders/output/feature_autoencoder_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Metadata-Input (InputLayer)  [(None, 4096)]            0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              1052672   \n",
      "=================================================================\n",
      "Total params: 2,106,890\n",
      "Trainable params: 2,106,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_layer=[]\n",
    "ae_encoder.layers.pop(0)\n",
    "for layer in ae_encoder.layers:\n",
    "    #layer.trainable=False\n",
    "    pretrained_layer.append(layer)\n",
    "ae_encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1c6ab897d0>,\n",
       " <tensorflow.python.keras.layers.noise.GaussianNoise at 0x1c4c4c1590>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c6c24f790>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c4c4c1150>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c422b3f90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c6b0501d0>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitching it together\n",
    "item_input = Input(shape=[1], name=\"Item-Input\")\n",
    "item_embedding = Embedding(input_dim=n_items+1, output_dim=embedding_size, name=\"Item-Embedding\")(item_input)\n",
    "item_vec = Flatten(name=\"Flatten-items\")(item_embedding)\n",
    "\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(input_dim=n_users+1, output_dim=embedding_size, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "#user_vec=Dropout(0.1)(user_vec)\n",
    "\n",
    "metadata_input=Input(shape=(metadata_input_dim,), name=\"Metadata-Input\")\n",
    "\n",
    "encoded=GaussianNoise(stddev=0.1)(metadata_input)\n",
    "encoded=pretrained_layer[1](encoded)\n",
    "encoded=pretrained_layer[2](encoded)\n",
    "metadata_vec=pretrained_layer[3](encoded)\n",
    "\n",
    "item_vec_augmented=Add()([metadata_vec, item_vec])\n",
    "item_vec_augmented=Dropout(0.1)(item_vec_augmented)\n",
    "'''\n",
    "metadata_vec=ae_encoder.get_layer(ae_encoder.layers)(metadata_input)\n",
    "'''\n",
    "prod = Dot(name=\"Dot-Product\", axes=1)([item_vec_augmented, user_vec])\n",
    "cdl_model = Model([user_input, item_input, metadata_input], prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.sqrt(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true), axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metric(y_true, y_pred):\n",
    "\n",
    "    y_true = y_true * tf.keras.backend.cast((y_true != 0),dtype='float32')\n",
    "    #y_true=y_true[np.nonzero(y_true)]\n",
    "    y_pred = y_pred * tf.keras.backend.cast((y_true != 0), dtype='float32')\n",
    "    #y_pred=y_pred[np.nonzero(y_true)]\n",
    "\n",
    "    error = root_mean_squared_error(y_true, y_pred)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdl_model.compile('adam', 'mean_squared_error') # we are trying to approximate a rating, so we use a regression measure: mse\n",
    "cdl_model.compile(optimizer='adadelta', \n",
    "                  loss=evaluation_metric,\n",
    "                  metrics=[evaluation_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\", \"<class 'numpy.ndarray'>\"}), <class 'NoneType'>\n",
      "Train on 173475 samples, validate on 43369 samples\n",
      "Epoch 1/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.8315 - evaluation_metric: 3.8315\n",
      "Epoch 00001: val_loss improved from inf to 3.82330, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 59s 343us/sample - loss: 3.8314 - evaluation_metric: 3.8314 - val_loss: 3.8233 - val_evaluation_metric: 3.8233\n",
      "Epoch 2/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.8266 - evaluation_metric: 3.8266\n",
      "Epoch 00002: val_loss improved from 3.82330 to 3.82054, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 63s 361us/sample - loss: 3.8266 - evaluation_metric: 3.8266 - val_loss: 3.8205 - val_evaluation_metric: 3.8205\n",
      "Epoch 3/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.8257 - evaluation_metric: 3.8257\n",
      "Epoch 00003: val_loss improved from 3.82054 to 3.81808, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 62s 355us/sample - loss: 3.8256 - evaluation_metric: 3.8256 - val_loss: 3.8181 - val_evaluation_metric: 3.8181\n",
      "Epoch 4/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.8215 - evaluation_metric: 3.8215\n",
      "Epoch 00004: val_loss improved from 3.81808 to 3.81588, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 62s 360us/sample - loss: 3.8214 - evaluation_metric: 3.8214 - val_loss: 3.8159 - val_evaluation_metric: 3.8159\n",
      "Epoch 5/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.8189 - evaluation_metric: 3.8189\n",
      "Epoch 00005: val_loss improved from 3.81588 to 3.81384, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 63s 362us/sample - loss: 3.8190 - evaluation_metric: 3.8190 - val_loss: 3.8138 - val_evaluation_metric: 3.8138\n",
      "Epoch 6/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.8164 - evaluation_metric: 3.8164\n",
      "Epoch 00006: val_loss improved from 3.81384 to 3.81193, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 63s 361us/sample - loss: 3.8164 - evaluation_metric: 3.8164 - val_loss: 3.8119 - val_evaluation_metric: 3.8119\n",
      "Epoch 7/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.8145 - evaluation_metric: 3.8145\n",
      "Epoch 00007: val_loss improved from 3.81193 to 3.81011, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 63s 363us/sample - loss: 3.8145 - evaluation_metric: 3.8145 - val_loss: 3.8101 - val_evaluation_metric: 3.8101\n",
      "Epoch 8/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.8131 - evaluation_metric: 3.8131\n",
      "Epoch 00008: val_loss improved from 3.81011 to 3.80837, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 62s 358us/sample - loss: 3.8130 - evaluation_metric: 3.8130 - val_loss: 3.8084 - val_evaluation_metric: 3.8084\n",
      "Epoch 9/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.8104 - evaluation_metric: 3.8104\n",
      "Epoch 00009: val_loss improved from 3.80837 to 3.80662, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 62s 357us/sample - loss: 3.8104 - evaluation_metric: 3.8104 - val_loss: 3.8066 - val_evaluation_metric: 3.8066\n",
      "Epoch 10/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.8095 - evaluation_metric: 3.8095\n",
      "Epoch 00010: val_loss improved from 3.80662 to 3.80486, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 62s 359us/sample - loss: 3.8095 - evaluation_metric: 3.8095 - val_loss: 3.8049 - val_evaluation_metric: 3.8049\n",
      "Epoch 11/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.8068 - evaluation_metric: 3.8068\n",
      "Epoch 00011: val_loss improved from 3.80486 to 3.80309, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 62s 357us/sample - loss: 3.8069 - evaluation_metric: 3.8069 - val_loss: 3.8031 - val_evaluation_metric: 3.8031\n",
      "Epoch 12/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.8055 - evaluation_metric: 3.8055\n",
      "Epoch 00012: val_loss improved from 3.80309 to 3.80128, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 63s 362us/sample - loss: 3.8056 - evaluation_metric: 3.8056 - val_loss: 3.8013 - val_evaluation_metric: 3.8013\n",
      "Epoch 13/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.8027 - evaluation_metric: 3.8027\n",
      "Epoch 00013: val_loss improved from 3.80128 to 3.79940, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 55s 317us/sample - loss: 3.8027 - evaluation_metric: 3.8027 - val_loss: 3.7994 - val_evaluation_metric: 3.7994\n",
      "Epoch 14/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.8015 - evaluation_metric: 3.8015\n",
      "Epoch 00014: val_loss improved from 3.79940 to 3.79746, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.8015 - evaluation_metric: 3.8015 - val_loss: 3.7975 - val_evaluation_metric: 3.7975\n",
      "Epoch 15/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.7983 - evaluation_metric: 3.7983\n",
      "Epoch 00015: val_loss improved from 3.79746 to 3.79544, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.7983 - evaluation_metric: 3.7983 - val_loss: 3.7954 - val_evaluation_metric: 3.7954\n",
      "Epoch 16/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.7971 - evaluation_metric: 3.7971\n",
      "Epoch 00016: val_loss improved from 3.79544 to 3.79333, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7971 - evaluation_metric: 3.7971 - val_loss: 3.7933 - val_evaluation_metric: 3.7933\n",
      "Epoch 17/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.7943 - evaluation_metric: 3.7943\n",
      "Epoch 00017: val_loss improved from 3.79333 to 3.79110, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 303us/sample - loss: 3.7942 - evaluation_metric: 3.7942 - val_loss: 3.7911 - val_evaluation_metric: 3.7911\n",
      "Epoch 18/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.7917 - evaluation_metric: 3.7917\n",
      "Epoch 00018: val_loss improved from 3.79110 to 3.78876, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.7917 - evaluation_metric: 3.7917 - val_loss: 3.7888 - val_evaluation_metric: 3.7888\n",
      "Epoch 19/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.7905 - evaluation_metric: 3.7904\n",
      "Epoch 00019: val_loss improved from 3.78876 to 3.78631, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 312us/sample - loss: 3.7905 - evaluation_metric: 3.7905 - val_loss: 3.7863 - val_evaluation_metric: 3.7863\n",
      "Epoch 20/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.7873 - evaluation_metric: 3.7873\n",
      "Epoch 00020: val_loss improved from 3.78631 to 3.78372, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7874 - evaluation_metric: 3.7874 - val_loss: 3.7837 - val_evaluation_metric: 3.7837\n",
      "Epoch 21/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.7839 - evaluation_metric: 3.7839\n",
      "Epoch 00021: val_loss improved from 3.78372 to 3.78100, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.7839 - evaluation_metric: 3.7839 - val_loss: 3.7810 - val_evaluation_metric: 3.7810\n",
      "Epoch 22/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.7810 - evaluation_metric: 3.7810\n",
      "Epoch 00022: val_loss improved from 3.78100 to 3.77809, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7810 - evaluation_metric: 3.7810 - val_loss: 3.7781 - val_evaluation_metric: 3.7781\n",
      "Epoch 23/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.7796 - evaluation_metric: 3.7796\n",
      "Epoch 00023: val_loss improved from 3.77809 to 3.77508, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.7797 - evaluation_metric: 3.7797 - val_loss: 3.7751 - val_evaluation_metric: 3.7751\n",
      "Epoch 24/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.7772 - evaluation_metric: 3.7773\n",
      "Epoch 00024: val_loss improved from 3.77508 to 3.77187, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7772 - evaluation_metric: 3.7772 - val_loss: 3.7719 - val_evaluation_metric: 3.7719\n",
      "Epoch 25/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.7718 - evaluation_metric: 3.7718\n",
      "Epoch 00025: val_loss improved from 3.77187 to 3.76847, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.7718 - evaluation_metric: 3.7718 - val_loss: 3.7685 - val_evaluation_metric: 3.7685\n",
      "Epoch 26/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.7679 - evaluation_metric: 3.7679\n",
      "Epoch 00026: val_loss improved from 3.76847 to 3.76481, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.7678 - evaluation_metric: 3.7678 - val_loss: 3.7648 - val_evaluation_metric: 3.7648\n",
      "Epoch 27/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.7670 - evaluation_metric: 3.7670\n",
      "Epoch 00027: val_loss improved from 3.76481 to 3.76103, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.7669 - evaluation_metric: 3.7669 - val_loss: 3.7610 - val_evaluation_metric: 3.7610\n",
      "Epoch 28/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.7634 - evaluation_metric: 3.7634\n",
      "Epoch 00028: val_loss improved from 3.76103 to 3.75703, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.7635 - evaluation_metric: 3.7635 - val_loss: 3.7570 - val_evaluation_metric: 3.7570\n",
      "Epoch 29/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.7575 - evaluation_metric: 3.7575\n",
      "Epoch 00029: val_loss improved from 3.75703 to 3.75273, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.7576 - evaluation_metric: 3.7576 - val_loss: 3.7527 - val_evaluation_metric: 3.7527\n",
      "Epoch 30/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.7549 - evaluation_metric: 3.7549\n",
      "Epoch 00030: val_loss improved from 3.75273 to 3.74827, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.7547 - evaluation_metric: 3.7547 - val_loss: 3.7483 - val_evaluation_metric: 3.7483\n",
      "Epoch 31/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.7504 - evaluation_metric: 3.7504\n",
      "Epoch 00031: val_loss improved from 3.74827 to 3.74361, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7504 - evaluation_metric: 3.7504 - val_loss: 3.7436 - val_evaluation_metric: 3.7436\n",
      "Epoch 32/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.7449 - evaluation_metric: 3.7449\n",
      "Epoch 00032: val_loss improved from 3.74361 to 3.73870, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7448 - evaluation_metric: 3.7448 - val_loss: 3.7387 - val_evaluation_metric: 3.7387\n",
      "Epoch 33/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.7397 - evaluation_metric: 3.7397\n",
      "Epoch 00033: val_loss improved from 3.73870 to 3.73351, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.7397 - evaluation_metric: 3.7397 - val_loss: 3.7335 - val_evaluation_metric: 3.7335\n",
      "Epoch 34/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.7349 - evaluation_metric: 3.7349\n",
      "Epoch 00034: val_loss improved from 3.73351 to 3.72812, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7350 - evaluation_metric: 3.7350 - val_loss: 3.7281 - val_evaluation_metric: 3.7281\n",
      "Epoch 35/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.7304 - evaluation_metric: 3.7303\n",
      "Epoch 00035: val_loss improved from 3.72812 to 3.72260, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.7303 - evaluation_metric: 3.7303 - val_loss: 3.7226 - val_evaluation_metric: 3.7226\n",
      "Epoch 36/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.7236 - evaluation_metric: 3.7236\n",
      "Epoch 00036: val_loss improved from 3.72260 to 3.71676, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.7238 - evaluation_metric: 3.7238 - val_loss: 3.7168 - val_evaluation_metric: 3.7168\n",
      "Epoch 37/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.7206 - evaluation_metric: 3.7206\n",
      "Epoch 00037: val_loss improved from 3.71676 to 3.71074, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.7205 - evaluation_metric: 3.7205 - val_loss: 3.7107 - val_evaluation_metric: 3.7107\n",
      "Epoch 38/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.7110 - evaluation_metric: 3.7110\n",
      "Epoch 00038: val_loss improved from 3.71074 to 3.70431, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.7109 - evaluation_metric: 3.7109 - val_loss: 3.7043 - val_evaluation_metric: 3.7043\n",
      "Epoch 39/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.7075 - evaluation_metric: 3.7075\n",
      "Epoch 00039: val_loss improved from 3.70431 to 3.69773, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 306us/sample - loss: 3.7075 - evaluation_metric: 3.7075 - val_loss: 3.6977 - val_evaluation_metric: 3.6977\n",
      "Epoch 40/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.6997 - evaluation_metric: 3.6997\n",
      "Epoch 00040: val_loss improved from 3.69773 to 3.69094, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 308us/sample - loss: 3.6999 - evaluation_metric: 3.6999 - val_loss: 3.6909 - val_evaluation_metric: 3.6909\n",
      "Epoch 41/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.6933 - evaluation_metric: 3.6933\n",
      "Epoch 00041: val_loss improved from 3.69094 to 3.68384, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 306us/sample - loss: 3.6933 - evaluation_metric: 3.6933 - val_loss: 3.6838 - val_evaluation_metric: 3.6838\n",
      "Epoch 42/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.6864 - evaluation_metric: 3.6864\n",
      "Epoch 00042: val_loss improved from 3.68384 to 3.67656, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 314us/sample - loss: 3.6863 - evaluation_metric: 3.6863 - val_loss: 3.6766 - val_evaluation_metric: 3.6766\n",
      "Epoch 43/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.6825 - evaluation_metric: 3.6825\n",
      "Epoch 00043: val_loss improved from 3.67656 to 3.66925, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 306us/sample - loss: 3.6825 - evaluation_metric: 3.6825 - val_loss: 3.6692 - val_evaluation_metric: 3.6692\n",
      "Epoch 44/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.6731 - evaluation_metric: 3.6731\n",
      "Epoch 00044: val_loss improved from 3.66925 to 3.66161, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 305us/sample - loss: 3.6731 - evaluation_metric: 3.6731 - val_loss: 3.6616 - val_evaluation_metric: 3.6616\n",
      "Epoch 45/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.6654 - evaluation_metric: 3.6654\n",
      "Epoch 00045: val_loss improved from 3.66161 to 3.65385, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.6654 - evaluation_metric: 3.6654 - val_loss: 3.6538 - val_evaluation_metric: 3.6538\n",
      "Epoch 46/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.6595 - evaluation_metric: 3.6595\n",
      "Epoch 00046: val_loss improved from 3.65385 to 3.64607, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.6595 - evaluation_metric: 3.6595 - val_loss: 3.6461 - val_evaluation_metric: 3.6461\n",
      "Epoch 47/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.6522 - evaluation_metric: 3.6522\n",
      "Epoch 00047: val_loss improved from 3.64607 to 3.63812, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.6522 - evaluation_metric: 3.6522 - val_loss: 3.6381 - val_evaluation_metric: 3.6381\n",
      "Epoch 48/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.6426 - evaluation_metric: 3.6426\n",
      "Epoch 00048: val_loss improved from 3.63812 to 3.62992, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.6426 - evaluation_metric: 3.6426 - val_loss: 3.6299 - val_evaluation_metric: 3.6299\n",
      "Epoch 49/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.6345 - evaluation_metric: 3.6345\n",
      "Epoch 00049: val_loss improved from 3.62992 to 3.62165, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.6345 - evaluation_metric: 3.6345 - val_loss: 3.6216 - val_evaluation_metric: 3.6216\n",
      "Epoch 50/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.6267 - evaluation_metric: 3.6267\n",
      "Epoch 00050: val_loss improved from 3.62165 to 3.61325, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.6270 - evaluation_metric: 3.6270 - val_loss: 3.6132 - val_evaluation_metric: 3.6132\n",
      "Epoch 51/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.6177 - evaluation_metric: 3.6178\n",
      "Epoch 00051: val_loss improved from 3.61325 to 3.60467, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.6177 - evaluation_metric: 3.6177 - val_loss: 3.6047 - val_evaluation_metric: 3.6047\n",
      "Epoch 52/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.6111 - evaluation_metric: 3.6111\n",
      "Epoch 00052: val_loss improved from 3.60467 to 3.59605, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 52s 300us/sample - loss: 3.6112 - evaluation_metric: 3.6112 - val_loss: 3.5961 - val_evaluation_metric: 3.5961\n",
      "Epoch 53/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.6050 - evaluation_metric: 3.6050\n",
      "Epoch 00053: val_loss improved from 3.59605 to 3.58731, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.6050 - evaluation_metric: 3.6050 - val_loss: 3.5873 - val_evaluation_metric: 3.5873\n",
      "Epoch 54/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.5947 - evaluation_metric: 3.5947\n",
      "Epoch 00054: val_loss improved from 3.58731 to 3.57834, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.5947 - evaluation_metric: 3.5947 - val_loss: 3.5783 - val_evaluation_metric: 3.5783\n",
      "Epoch 55/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.5825 - evaluation_metric: 3.5825\n",
      "Epoch 00055: val_loss improved from 3.57834 to 3.56919, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.5825 - evaluation_metric: 3.5825 - val_loss: 3.5692 - val_evaluation_metric: 3.5692\n",
      "Epoch 56/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.5746 - evaluation_metric: 3.5746\n",
      "Epoch 00056: val_loss improved from 3.56919 to 3.56007, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.5746 - evaluation_metric: 3.5746 - val_loss: 3.5601 - val_evaluation_metric: 3.5601\n",
      "Epoch 57/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.5653 - evaluation_metric: 3.5653\n",
      "Epoch 00057: val_loss improved from 3.56007 to 3.55072, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.5653 - evaluation_metric: 3.5653 - val_loss: 3.5507 - val_evaluation_metric: 3.5507\n",
      "Epoch 58/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.5567 - evaluation_metric: 3.5567\n",
      "Epoch 00058: val_loss improved from 3.55072 to 3.54126, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.5566 - evaluation_metric: 3.5566 - val_loss: 3.5413 - val_evaluation_metric: 3.5413\n",
      "Epoch 59/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.5498 - evaluation_metric: 3.5498\n",
      "Epoch 00059: val_loss improved from 3.54126 to 3.53148, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.5497 - evaluation_metric: 3.5497 - val_loss: 3.5315 - val_evaluation_metric: 3.5315\n",
      "Epoch 60/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.5400 - evaluation_metric: 3.5400\n",
      "Epoch 00060: val_loss improved from 3.53148 to 3.52178, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.5401 - evaluation_metric: 3.5401 - val_loss: 3.5218 - val_evaluation_metric: 3.5218\n",
      "Epoch 61/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.5296 - evaluation_metric: 3.5296\n",
      "Epoch 00061: val_loss improved from 3.52178 to 3.51182, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 306us/sample - loss: 3.5297 - evaluation_metric: 3.5297 - val_loss: 3.5118 - val_evaluation_metric: 3.5118\n",
      "Epoch 62/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.5199 - evaluation_metric: 3.5199\n",
      "Epoch 00062: val_loss improved from 3.51182 to 3.50178, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.5199 - evaluation_metric: 3.5199 - val_loss: 3.5018 - val_evaluation_metric: 3.5018\n",
      "Epoch 63/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.5098 - evaluation_metric: 3.5098\n",
      "Epoch 00063: val_loss improved from 3.50178 to 3.49163, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 313us/sample - loss: 3.5100 - evaluation_metric: 3.5100 - val_loss: 3.4916 - val_evaluation_metric: 3.4916\n",
      "Epoch 64/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.5008 - evaluation_metric: 3.5008\n",
      "Epoch 00064: val_loss improved from 3.49163 to 3.48141, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 306us/sample - loss: 3.5010 - evaluation_metric: 3.5010 - val_loss: 3.4814 - val_evaluation_metric: 3.4814\n",
      "Epoch 65/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.4910 - evaluation_metric: 3.4910\n",
      "Epoch 00065: val_loss improved from 3.48141 to 3.47106, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.4910 - evaluation_metric: 3.4910 - val_loss: 3.4711 - val_evaluation_metric: 3.4711\n",
      "Epoch 66/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.4819 - evaluation_metric: 3.4819\n",
      "Epoch 00066: val_loss improved from 3.47106 to 3.46055, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.4820 - evaluation_metric: 3.4820 - val_loss: 3.4605 - val_evaluation_metric: 3.4605\n",
      "Epoch 67/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.4703 - evaluation_metric: 3.4703\n",
      "Epoch 00067: val_loss improved from 3.46055 to 3.44997, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.4702 - evaluation_metric: 3.4702 - val_loss: 3.4500 - val_evaluation_metric: 3.4500\n",
      "Epoch 68/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.4611 - evaluation_metric: 3.4611\n",
      "Epoch 00068: val_loss improved from 3.44997 to 3.43924, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.4612 - evaluation_metric: 3.4612 - val_loss: 3.4392 - val_evaluation_metric: 3.4392\n",
      "Epoch 69/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.4498 - evaluation_metric: 3.4498\n",
      "Epoch 00069: val_loss improved from 3.43924 to 3.42819, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.4500 - evaluation_metric: 3.4500 - val_loss: 3.4282 - val_evaluation_metric: 3.4282\n",
      "Epoch 70/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.4391 - evaluation_metric: 3.4391\n",
      "Epoch 00070: val_loss improved from 3.42819 to 3.41718, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.4391 - evaluation_metric: 3.4391 - val_loss: 3.4172 - val_evaluation_metric: 3.4172\n",
      "Epoch 71/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.4307 - evaluation_metric: 3.4307\n",
      "Epoch 00071: val_loss improved from 3.41718 to 3.40606, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 305us/sample - loss: 3.4309 - evaluation_metric: 3.4309 - val_loss: 3.4061 - val_evaluation_metric: 3.4061\n",
      "Epoch 72/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.4203 - evaluation_metric: 3.4203\n",
      "Epoch 00072: val_loss improved from 3.40606 to 3.39484, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.4203 - evaluation_metric: 3.4203 - val_loss: 3.3948 - val_evaluation_metric: 3.3948\n",
      "Epoch 73/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.4065 - evaluation_metric: 3.4066\n",
      "Epoch 00073: val_loss improved from 3.39484 to 3.38318, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.4066 - evaluation_metric: 3.4066 - val_loss: 3.3832 - val_evaluation_metric: 3.3832\n",
      "Epoch 74/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.4001 - evaluation_metric: 3.4001\n",
      "Epoch 00074: val_loss improved from 3.38318 to 3.37172, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 312us/sample - loss: 3.3999 - evaluation_metric: 3.3999 - val_loss: 3.3717 - val_evaluation_metric: 3.3717\n",
      "Epoch 75/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.3895 - evaluation_metric: 3.3895\n",
      "Epoch 00075: val_loss improved from 3.37172 to 3.36031, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 55s 317us/sample - loss: 3.3897 - evaluation_metric: 3.3897 - val_loss: 3.3603 - val_evaluation_metric: 3.3603\n",
      "Epoch 76/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.3754 - evaluation_metric: 3.3754\n",
      "Epoch 00076: val_loss improved from 3.36031 to 3.34859, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.3754 - evaluation_metric: 3.3754 - val_loss: 3.3486 - val_evaluation_metric: 3.3486\n",
      "Epoch 77/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.3633 - evaluation_metric: 3.3633\n",
      "Epoch 00077: val_loss improved from 3.34859 to 3.33684, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 305us/sample - loss: 3.3633 - evaluation_metric: 3.3633 - val_loss: 3.3368 - val_evaluation_metric: 3.3368\n",
      "Epoch 78/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.3546 - evaluation_metric: 3.3546\n",
      "Epoch 00078: val_loss improved from 3.33684 to 3.32494, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.3546 - evaluation_metric: 3.3546 - val_loss: 3.3249 - val_evaluation_metric: 3.3249\n",
      "Epoch 79/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.3424 - evaluation_metric: 3.3424\n",
      "Epoch 00079: val_loss improved from 3.32494 to 3.31301, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.3424 - evaluation_metric: 3.3424 - val_loss: 3.3130 - val_evaluation_metric: 3.3130\n",
      "Epoch 80/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.3298 - evaluation_metric: 3.3298\n",
      "Epoch 00080: val_loss improved from 3.31301 to 3.30094, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 305us/sample - loss: 3.3299 - evaluation_metric: 3.3299 - val_loss: 3.3009 - val_evaluation_metric: 3.3009\n",
      "Epoch 81/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.3182 - evaluation_metric: 3.3182\n",
      "Epoch 00081: val_loss improved from 3.30094 to 3.28892, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.3181 - evaluation_metric: 3.3181 - val_loss: 3.2889 - val_evaluation_metric: 3.2889\n",
      "Epoch 82/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.3100 - evaluation_metric: 3.3100\n",
      "Epoch 00082: val_loss improved from 3.28892 to 3.27673, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.3101 - evaluation_metric: 3.3101 - val_loss: 3.2767 - val_evaluation_metric: 3.2767\n",
      "Epoch 83/100\n",
      "173408/173475 [============================>.] - ETA: 0s - loss: 3.2955 - evaluation_metric: 3.2954\n",
      "Epoch 00083: val_loss improved from 3.27673 to 3.26453, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.2954 - evaluation_metric: 3.2954 - val_loss: 3.2645 - val_evaluation_metric: 3.2645\n",
      "Epoch 84/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.2836 - evaluation_metric: 3.2836\n",
      "Epoch 00084: val_loss improved from 3.26453 to 3.25214, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.2835 - evaluation_metric: 3.2835 - val_loss: 3.2521 - val_evaluation_metric: 3.2521\n",
      "Epoch 85/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.2706 - evaluation_metric: 3.2706\n",
      "Epoch 00085: val_loss improved from 3.25214 to 3.23972, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.2707 - evaluation_metric: 3.2707 - val_loss: 3.2397 - val_evaluation_metric: 3.2397\n",
      "Epoch 86/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.2627 - evaluation_metric: 3.2627\n",
      "Epoch 00086: val_loss improved from 3.23972 to 3.22741, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.2627 - evaluation_metric: 3.2627 - val_loss: 3.2274 - val_evaluation_metric: 3.2274\n",
      "Epoch 87/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.2453 - evaluation_metric: 3.2453\n",
      "Epoch 00087: val_loss improved from 3.22741 to 3.21485, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.2454 - evaluation_metric: 3.2454 - val_loss: 3.2149 - val_evaluation_metric: 3.2149\n",
      "Epoch 88/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.2377 - evaluation_metric: 3.2377\n",
      "Epoch 00088: val_loss improved from 3.21485 to 3.20252, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.2378 - evaluation_metric: 3.2378 - val_loss: 3.2025 - val_evaluation_metric: 3.2025\n",
      "Epoch 89/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.2237 - evaluation_metric: 3.2237\n",
      "Epoch 00089: val_loss improved from 3.20252 to 3.18986, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 312us/sample - loss: 3.2234 - evaluation_metric: 3.2234 - val_loss: 3.1899 - val_evaluation_metric: 3.1899\n",
      "Epoch 90/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.2123 - evaluation_metric: 3.2123\n",
      "Epoch 00090: val_loss improved from 3.18986 to 3.17716, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.2123 - evaluation_metric: 3.2123 - val_loss: 3.1772 - val_evaluation_metric: 3.1772\n",
      "Epoch 91/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.1991 - evaluation_metric: 3.1991\n",
      "Epoch 00091: val_loss improved from 3.17716 to 3.16424, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.1991 - evaluation_metric: 3.1991 - val_loss: 3.1642 - val_evaluation_metric: 3.1642\n",
      "Epoch 92/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.1930 - evaluation_metric: 3.1930\n",
      "Epoch 00092: val_loss improved from 3.16424 to 3.15169, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 309us/sample - loss: 3.1929 - evaluation_metric: 3.1929 - val_loss: 3.1517 - val_evaluation_metric: 3.1517\n",
      "Epoch 93/100\n",
      "173472/173475 [============================>.] - ETA: 0s - loss: 3.1765 - evaluation_metric: 3.1765\n",
      "Epoch 00093: val_loss improved from 3.15169 to 3.13892, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.1765 - evaluation_metric: 3.1765 - val_loss: 3.1389 - val_evaluation_metric: 3.1389\n",
      "Epoch 94/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.1625 - evaluation_metric: 3.1625\n",
      "Epoch 00094: val_loss improved from 3.13892 to 3.12600, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.1624 - evaluation_metric: 3.1624 - val_loss: 3.1260 - val_evaluation_metric: 3.1260\n",
      "Epoch 95/100\n",
      "173440/173475 [============================>.] - ETA: 0s - loss: 3.1517 - evaluation_metric: 3.1517\n",
      "Epoch 00095: val_loss improved from 3.12600 to 3.11310, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 308us/sample - loss: 3.1517 - evaluation_metric: 3.1517 - val_loss: 3.1131 - val_evaluation_metric: 3.1131\n",
      "Epoch 96/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.1396 - evaluation_metric: 3.1396\n",
      "Epoch 00096: val_loss improved from 3.11310 to 3.10017, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 314us/sample - loss: 3.1398 - evaluation_metric: 3.1398 - val_loss: 3.1002 - val_evaluation_metric: 3.1002\n",
      "Epoch 97/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.1277 - evaluation_metric: 3.1277\n",
      "Epoch 00097: val_loss improved from 3.10017 to 3.08715, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.1276 - evaluation_metric: 3.1276 - val_loss: 3.0872 - val_evaluation_metric: 3.0871\n",
      "Epoch 98/100\n",
      "173376/173475 [============================>.] - ETA: 0s - loss: 3.1141 - evaluation_metric: 3.1141\n",
      "Epoch 00098: val_loss improved from 3.08715 to 3.07415, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 310us/sample - loss: 3.1141 - evaluation_metric: 3.1141 - val_loss: 3.0741 - val_evaluation_metric: 3.0741\n",
      "Epoch 99/100\n",
      "173312/173475 [============================>.] - ETA: 0s - loss: 3.1013 - evaluation_metric: 3.1013\n",
      "Epoch 00099: val_loss improved from 3.07415 to 3.06132, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 53s 307us/sample - loss: 3.1014 - evaluation_metric: 3.1014 - val_loss: 3.0613 - val_evaluation_metric: 3.0613\n",
      "Epoch 100/100\n",
      "173344/173475 [============================>.] - ETA: 0s - loss: 3.0906 - evaluation_metric: 3.0906\n",
      "Epoch 00100: val_loss improved from 3.06132 to 3.04852, saving model to Recommenders/output/cdl_model_1.h5\n",
      "173475/173475 [==============================] - 54s 311us/sample - loss: 3.0905 - evaluation_metric: 3.0905 - val_loss: 3.0485 - val_evaluation_metric: 3.0485\n"
     ]
    }
   ],
   "source": [
    "## train new model with sampling\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "\n",
    "container = \"Recommenders/\"\n",
    "outputFilePath=container+\"output/\"+'cdl_model_1.h5'\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=outputFilePath,\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                         patience=10,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights=True\n",
    "                         )\n",
    "\n",
    "history = cdl_model.fit([train.user_id, train.item_id, np.vstack(train.features)], train.rating,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, earlystop]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train, Val Error\")\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for making recommendations for the first user\n",
    "#watch_data = np.array(list(set(new_dataset.item_id)))\n",
    "watch_data=np.array(new_dataset.item_id)\n",
    "picture_data= np.vstack(new_dataset.features)\n",
    "user_data = np.array([1 for i in range(len(watch_data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39152, 39126, 39127, 39128, 39129])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = cdl_model.predict([user_data, watch_data, np.vstack(picture_data)])\n",
    "\n",
    "predictions = np.array([a[0] for a in predictions])\n",
    "\n",
    "recommended_watch_ids = (-predictions).argsort()[:5]\n",
    "\n",
    "recommended_watch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
